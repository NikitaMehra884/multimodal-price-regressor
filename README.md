# ğŸ›ï¸ Multimodal Price Regressor ğŸ’°

An **end-to-end machine learning project** to predict **e-commerce product prices** from **multi-modal data** (text + images).  
This solution employs a **feature fusion strategy**, combining **advanced NLP** features from product descriptions with **computer vision** features from product images.  
An ensemble of **gradient boosting models** is then trained on the combined feature set to perform the final price regression.

---

## ğŸ“œ Overview

The goal of this project is to **accurately estimate the price** of an online product given its catalog description and image.  
This is a **classic regression** problem with a **multi-modal twist**.

The solution pipeline includes:
- Data ingestion & cleaning
- Feature engineering
- Memory-efficient processing
- Model training
- Final price prediction

---

## ğŸ› ï¸ Tech Stack

**Language:** Python 3.11+  

**Core Libraries:**
- ğŸ§® Data Handling: `Pandas`, `NumPy`
- ğŸ¤– Machine Learning: `Scikit-learn`, `LightGBM`, `XGBoost`
- ğŸ§  Deep Learning: `TensorFlow`, `PyTorch`, `Transformers`
- ğŸ–¼ï¸ Image Processing: `Pillow`
- âš¡ Utilities: `Tqdm`, `Requests`, `Joblib`

**Environment:** Jupyter Notebook, VS Code

---

## ğŸ“ Project Structure
```
multimodal-price-regressor/
â”‚
â”œâ”€â”€ dataset/
â”‚ â”œâ”€â”€ train.csv
â”‚ â””â”€â”€ test.csv
â”‚
â”œâ”€â”€ images/
â”‚ â””â”€â”€ (Downloaded product images...)
â”‚
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ price_prediction.ipynb # Main Jupyter Notebook
â”‚
â”œâ”€â”€ saved_features/
â”‚ â”œâ”€â”€ distilbert_embeddings.npy
â”‚ â”œâ”€â”€ X_img_train.npy
â”‚ â””â”€â”€ X_img_test.npy
â”‚
â”œâ”€â”€ utils.py # Helper functions (e.g., parallel image downloader)
â”œâ”€â”€ requirements.txt # Project dependencies
â””â”€â”€ README.md
---
```
## ğŸ§  Methodology

The solution is built on a robust pipeline that **processes and combines features** from different data sources before feeding them into a **powerful ensemble model**.

### 1. ğŸ§¼ Data Preprocessing
* **Text Cleaning:**  
  - Convert text to lowercase  
  - Remove HTML tags, punctuation, and stopwords  
  - Retain meaningful words for better feature extraction

* **Image Downloading:**  
  - A parallel downloader (`utils.py`) fetches and saves product images  
  - Handles errors, retries, and timeouts efficiently

---

### 2. ğŸ§¬ Feature Engineering

#### ğŸ“ Text Features (Hybrid)
* **TF-IDF:** Capture keyword importance and frequency (top 1500 terms)
* **DistilBERT:** Generate dense semantic embeddings for deeper context

#### ğŸ–¼ï¸ Image Features
* **ResNet50 (pre-trained):**  
  - Images resized to 224x224  
  - Extract 2048-dimensional visual feature vector

#### ğŸ§­ Feature Reduction (PCA)
* BERT (768 â†’ **128** dimensions)
* ResNet50 (2048 â†’ **256** dimensions)

#### ğŸ”— Feature Fusion
* Final feature vector = **TF-IDF (1500)** + **BERT (128)** + **Image (256)**

---

### 3. ğŸ“Š Modeling & Evaluation

* **Ensemble Models:** `LightGBM` + `XGBoost`
* **Prediction Averaging:** 50/50 average of both modelsâ€™ outputs
* **Target Transformation:**  
  - `log1p` before training  
  - `expm1` after prediction
* **Evaluation Metric:** SMAPE (Symmetric Mean Absolute Percentage Error)
* **Cross Validation:** 5-Fold CV for stable performance

---

## ğŸš€ Setup & Usage

### 1. Clone the repository

git clone https://github.com/your-username/multimodal-price-regressor.git
cd multimodal-price-regressor
python -m venv venv
.\venv\Scripts\activate       # (Windows)
# source venv/bin/activate    # (Mac/Linux)

pip install -r requirements.txt
## ğŸ§ª 3. Run the Jupyter Notebook

1. **Open the project** in **VS Code**
2. Navigate to:
notebooks/price_prediction.ipynb
3. **Run all cells sequentially** to:
- ğŸ“¥ Download data
- ğŸ§¬ Extract features
- ğŸ¤– Train models
- ğŸ“ˆ Generate predictions

ğŸ’¡ **Note:**  
The first run may take longer due to feature extraction,  
but outputs are saved as `.npy` files for **faster reuse** in future runs.

---

## ğŸ¯ Results

- âœ… **Final Ensemble Model:** Competitive SMAPE Score  
- ğŸ† **Best Local CV Score:** `52.xx %` *(example)*

---

## ğŸ”® Future Scope

- âš¡ **Advanced Ensembling:** Replace simple averaging with **stacking**
- ğŸ§ª **Hyperparameter Tuning:** Use `Optuna` for optimal model parameters
- ğŸ—ï¸ **Different Architectures:** Try `EfficientNet` for images or other `BERT` variants for text

---

## âœ¨ Acknowledgments

- ğŸ¤ [Hugging Face Transformers](https://huggingface.co/)
- ğŸ”¥ [PyTorch](https://pytorch.org/) & [TensorFlow](https://www.tensorflow.org/) Communities
- ğŸŒ¿ [LightGBM](https://github.com/microsoft/LightGBM) & [XGBoost](https://github.com/dmlc/xgboost) Contributors

---

## ğŸ“ License

This project is licensed under the **MIT License**.

---

âœ… **Tip:** You can also add badges like Python version, build status, or license at the top of your README to make it look even more professional.  

Would you like me to **add badges and a small banner image section** too (like top GitHub repos have)? ğŸš€

